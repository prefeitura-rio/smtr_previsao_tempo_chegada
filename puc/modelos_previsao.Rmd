---
title: "R Notebook"
output: html_notebook
---

```{r, message = FALSE, warning = FALSE}
library(basedosdados)
library(dplyr)
library(ggplot2)
library(knitr)
library(fixest)
library(data.table)
library(randomForest)
library(ranger)
library(neuralnet)

# projeto google cloud
set_billing_id("absolute-text-417919") 

# caminho para os dados mais pesados
source <- "F:/Dados/SMTR"
```

Lendo os dados: base de treino, de 04/03/2024 a 08/03/2024 (dias de semana), e base de teste, de 11/03/2024 a 12/04/2024.

```{r, message = FALSE}
training_data <- fread(file.path(source, "gps_training_1_10.csv")) %>%
    slice_sample(n = 1000000)

test_data <- fread(file.path(source, "gps_test_1_10.csv")) %>%
    slice_sample(n = 1000000)

training_data$hora <- as.numeric(substr(training_data$hora, 1, 2))

test_data$hora <- as.numeric(substr(test_data$hora, 1, 2))
```

## Medidas de erro

* Erro quadrático médio

\[
\mathrm{MSE} = \frac{1}{n}\sum_i \big(y_i - \widehat{y}_i\big)^2, \quad \mathrm{RMSE} = \sqrt{\mathrm{MSE}}.
\]

* Erro absoluto médio

\[
\mathrm{MAE} = \frac{1}{n}\sum_i \big\lvert y_i - \widehat{y}_i\big\rvert.
\]

* Erro Absoluto Percentual Médio

\[
\mathrm{MAPE} = \frac{1}{n}\sum_i \frac{\lvert y_i - \widehat{y}_i\rvert}{y_i}.
\]

* Desvio absoluto mediano

\[
\mathrm{MAD} = \mathrm{median}\Big(\big\lvert e_i - \mathrm{median}(e_i)\big\rvert\Big), \quad\text{onde $e_i = y_i - \widehat{y}_i$}.
\]

## Benchmark: médias de chegada de cada linha

\[
\widehat{y}_i = \text{média de tempos de chegada do serviço ao ponto}
\]

```{r, echo = FALSE}
# setup da tabela que armazena os resultados

models <- data.frame(
    "Modelo" = character(), "RMSE" = double(), "MAE" = double(), "MAPE" = double(), "MAD" = double()
)

# função que produz medidas de erro

prediction_errors <- function(df, modelo) {
    by_stop <- df %>%
        mutate(error = arrival_time - est_arrival_time) %>%
        summarise(
            Modelo = modelo,
            RMSE = sqrt(mean(error^2, na.rm = TRUE)),
            MAE = mean(abs(error), na.rm = TRUE),
            MAPE = mean(abs(error)/arrival_time, na.rm = TRUE),
            MAD = median(abs(error - median(error, na.rm = TRUE)), na.rm = TRUE),
            .by = "stop_order"
        ) %>%
        arrange(stop_order) %>%
        rename("Ordem do ponto" = stop_order) %>%
        mutate(across(`Ordem do ponto`, as.character))
    
    total <- df %>%
        mutate(error = arrival_time - est_arrival_time) %>%
        summarise(
            `Ordem do ponto` = "Total",
            Modelo = modelo,
            RMSE = sqrt(mean(error^2, na.rm = TRUE)),
            MAE = mean(abs(error), na.rm = TRUE),
            MAPE = mean(abs(error)/arrival_time, na.rm = TRUE),
            MAD = median(abs(error - median(error, na.rm = TRUE)), na.rm = TRUE)
        )
    
    bind_rows(total, by_stop)
}
```

```{r, message = FALSE}
bench <- training_data %>%
    summarise(
        est_arrival_time = mean(arrival_time, na.rm = TRUE),
        .by = c("servico", "stop_id", "stop_order")
    )
```


```{r, echo = FALSE, message = FALSE}
bench <- test_data %>%
    left_join(bench, by = c("servico", "stop_id", "stop_order"))

bench <- prediction_errors(bench, "Médias históricas")

models <- models %>%
    bind_rows(bench[1,-1])

kable(bench, digits = 1)
```


## Modelo Newtoniano

\[
\widehat{y}_i = \frac{\text{distância até o próx. ponto}}{\text{velocidade média últimos 10mins}}
\]

```{r, message = FALSE}
newton <- test_data %>%
    mutate(
        est_arrival_time = 60/1000 * dist_to_stop/velocidade_estimada_10_min
    )
```


```{r, echo = FALSE}
newton <- prediction_errors(newton, "Newtoniano")

models <- models %>%
    bind_rows(newton[1,-1])

kable(newton, digits = 1)
```

## Regressão linear

\[
\widehat{y}_i = \alpha_{i, t, \text{parada}} + \beta\,\text{distância} + \gamma\,v_\text{10mins} + \delta\, v_\text{inst}
\]

```{r, message = FALSE}
reg_newton <- feols(
    arrival_time ~ dist_to_stop + velocidade_estimada_10_min + velocidade_instantanea |
        servico + hora + stop_id + stop_order,
    data = training_data
)
```


```{r, echo = FALSE}
reg_newton <- test_data %>%
    bind_cols("est_arrival_time" = predict(reg_newton, test_data)) %>%
    mutate(error = (arrival_time - est_arrival_time)) %>%
    prediction_errors("Regressão")

models <- models %>%
    bind_rows(reg_newton[1,-1])

kable(reg_newton, digits = 1)
```

## Regressão linear com interações

\[
\widehat{y}_i = \alpha_{i, t, \text{parada}} + \beta_{i, t, \text{parada}}\,\text{distância} + \gamma\,v_\text{10mins} + \delta\, v_\text{inst}
\]

```{r, message = FALSE}
fe_reg <- feols(
    arrival_time ~ dist_to_stop + velocidade_estimada_10_min + velocidade_instantanea |
        servico[dist_to_stop] + hora[dist_to_stop] + stop_id[dist_to_stop] + stop_order[dist_to_stop],
    data = training_data
)
```


```{r, echo = FALSE}
# Calculando performance

fe_reg <- test_data %>%
    bind_cols("est_arrival_time" = predict(fe_reg, test_data)) %>%
    prediction_errors("Regressão com interações")

models <- models %>%
    bind_rows(fe_reg[1,-1])

kable(fe_reg, digits = 1)
```

## Random Forest

```{r, message = FALSE}

rf <- ranger(
    arrival_time ~ hora + latitude + longitude + velocidade_instantanea + velocidade_estimada_10_min +
        dist_traveled_shape + dist_to_stop + stop_order + stop_sequence,
    data = training_data,
    num.trees = 300,
    max.depth = 20
)
```


```{r, echo = FALSE}

rf <- test_data %>%
    bind_cols("est_arrival_time" = predict(rf, test_data)$predictions) %>%
    prediction_errors("Random Forest")

models <- models %>%
    bind_rows(rf[1,-1])

kable(rf, digits = 1)
```

## Rede Neural

```{r}
training_data <- training_data %>%
    slice_sample(n = 10000)

y_train <- training_data$arrival_time

x_train <- training_data %>%
    select(
        hora, latitude, longitude, velocidade_instantanea, velocidade_estimada_10_min,
        dist_traveled_shape, dist_to_stop, stop_sequence, stop_order
    ) %>%
    as.matrix()

y_test <-  test_data$arrival_time

x_test <- test_data %>%
    select(
        hora, latitude, longitude, velocidade_instantanea, velocidade_estimada_10_min,
        dist_traveled_shape, dist_to_stop, stop_sequence, stop_order
    ) %>%
    as.matrix()

# computando medias e desvios padrão do treino para normalizar

y_mean <- mean(y_train)

y_sd <- sd(y_train)

x_mean <- colMeans(x_train)

x_sd <- apply(x_train, 2, sd)

# normalizando bases

y_train <- (y_train - y_mean)/y_sd

x_train <- t((t(x_train) - x_mean)/x_sd)

y_test <- (y_test - y_mean)/y_sd

x_test <- t((t(x_test) - x_mean)/x_sd)

# convertendo de volta em data frame

training_data <- data.frame(
    "arrival_time" = y_train, x_train
)

test_data <- data.frame(
    "arrival_time" = y_test, x_test
)

# treinando a rede

nn <- neuralnet(
    arrival_time ~ hora + latitude + longitude + velocidade_instantanea + velocidade_estimada_10_min +
        dist_traveled_shape + dist_to_stop + stop_order + stop_sequence,
    data = training_data,
    hidden = 5,
    lifesign = "full",
    stepmax = 1e+06,
    threshold = 0.1
)

# previsões
# desnormalizando

pred <- predict(nn, test_data) * y_sd + y_mean

nn <- test_data %>%
    bind_cols("est_arrival_time" = pred) %>%
    mutate(stop_order = round(stop_order * x_sd["stop_order"] + x_mean["stop_order"])) %>%
    mutate(arrival_time = arrival_time * y_sd + y_mean) %>%
    prediction_errors("Neural Network")

models <- models %>%
    bind_rows(nn[1,-1])

kable(nn, digits = 1)
```


## Comparativo

```{r}
kable(models, digits = 1)
```


